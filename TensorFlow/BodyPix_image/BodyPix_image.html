<!-- 
Author : ChungYi Fu (Kaohsiung, Taiwan)   2019/6/7
https://www.facebook.com/francefu

Try it!
https://fustyles.github.io/webduino/TensorFlow/BodyPix_image/BodyPix_image.html
-->
<!DOCTYPE html>
<head>
  <title>person and body part segmentation (BodyPix)</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0"> </script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@1.0.0"> </script> 
</head>
<body>
<input type="file" id="selectimage" disabled="true"></input>
<br>
<div id="result" style="width:350px;color:red">Please wait for loading model.</div>
<br><br>
<img id="OriginImage" style="display:none"><br>
<canvas id="ShowImage"></canvas><br>
<canvas id="canvas1"></canvas><br>
<canvas id="canvas2"></canvas><br>
<canvas id="canvas3"></canvas><br>
<canvas id="canvas4"></canvas>

<script>
var OriginImage = document.getElementById('OriginImage');
var ShowImage = document.getElementById('ShowImage');
var context = ShowImage.getContext("2d");
var ShowImageWidth = 500;
var canvas1 = document.getElementById("canvas1");
var canvas2 = document.getElementById("canvas2");
var canvas3 = document.getElementById("canvas3");
var canvas4 = document.getElementById("canvas4");
var result = document.getElementById('result');
var Model;
var outputStride = 16;
var segmentationThreshold = 0.5;
  
function ObjectDetect() {
  bodyPix.load().then(function(net) {
    Model = net;
    result.innerHTML = "Please select one image.";
    document.getElementById('selectimage').disabled = false;
  }); 
}
  
async function DetectImage() {
  await Model.estimatePersonSegmentation(ShowImage, outputStride, segmentationThreshold).then(segmentation => {
    //console.log(segmentation);
    canvas1.setAttribute("width", ShowImage.width);
    canvas1.setAttribute("height", ShowImage.height);   
    canvas2.setAttribute("width", ShowImage.width);
    canvas2.setAttribute("height", ShowImage.height); 
    canvas3.setAttribute("width", ShowImage.width);
    canvas3.setAttribute("height", ShowImage.height); 
    canvas4.setAttribute("width", ShowImage.width);
    canvas4.setAttribute("height", ShowImage.height);	  
    
    const maskBackground = true;
    // Convert the personSegmentation into a mask to darken the background.
    // Since maskBackground is set to true, there will be 1s where the background is and 0s where the person is.
    const backgroundDarkeningMask = bodyPix.toMaskImageData(segmentation, maskBackground);
    const opacity = 0.8;
    const maskBlurAmount = 3;
    const flipHorizontal = false;
    const backgroundBlurAmount = 3;
    const edgeBlurAmount = 3;
    // draw the mask onto the image on a canvas.  With opacity set to 0.7 and maskBlurAmount set to 3, this will darken the background and blur the darkened background's edge.
    bodyPix.drawMask(canvas1, ShowImage, backgroundDarkeningMask, opacity, maskBlurAmount, flipHorizontal);
	  
    bodyPix.drawBokehEffect(canvas2, ShowImage, segmentation, backgroundBlurAmount, edgeBlurAmount, flipHorizontal);
	  
    const rainbow = [
      [110, 64, 170], [143, 61, 178], [178, 60, 178], [210, 62, 167],
      [238, 67, 149], [255, 78, 125], [255, 94, 99],  [255, 115, 75],
      [255, 140, 56], [239, 167, 47], [217, 194, 49], [194, 219, 64],
      [175, 240, 91], [135, 245, 87], [96, 247, 96],  [64, 243, 115],
      [40, 234, 141], [28, 219, 169], [26, 199, 194], [33, 176, 213],
      [47, 150, 224], [65, 125, 224], [84, 101, 214], [99, 81, 195]
    ];
    const coloredPartImageData = bodyPix.toColoredPartImageData(segmentation, rainbow);
    const pixelCellWidth = 10.0;
    bodyPix.drawPixelatedMask(canvas3, ShowImage, coloredPartImageData, opacity, maskBlurAmount, flipHorizontal, pixelCellWidth);	  
    
	  const warm = [
      [110, 64, 170], [106, 72, 183], [100, 81, 196], [92, 91, 206],
      [84, 101, 214], [75, 113, 221], [66, 125, 224], [56, 138, 226],
      [48, 150, 224], [40, 163, 220], [33, 176, 214], [29, 188, 205],
      [26, 199, 194], [26, 210, 182], [28, 219, 169], [33, 227, 155],
      [41, 234, 141], [51, 240, 128], [64, 243, 116], [79, 246, 105],
      [96, 247, 97],  [115, 246, 91], [134, 245, 88], [155, 243, 88]
    ];
    const coloredPartImage = bodyPix.toColoredPartImageData(segmentation, warm);
    bodyPix.drawMask(canvas4, ShowImage, coloredPartImage, 1.0, maskBlurAmount, flipHorizontal);
	 
    result.innerHTML = "";
  });
}
    
document.getElementById('selectimage').onchange = function (event) {
  var target = event.target || window.event.srcElement;
  var files = target.files;
  if (FileReader && files && files.length) {
    var fr = new FileReader();
    fr.onload = function () {
      result.innerHTML = "Loading image to detect...";  
      OriginImage.src = fr.result;
    }
    fr.readAsDataURL(files[0]);
  }
}
  
document.getElementById('OriginImage').onload = function (event) {
  try { 
    document.createEvent("TouchEvent"); 
    var width = document.body.clientWidth;
  }
  catch(e) { 
    var width = ShowImageWidth;
  } 
  
  if (OriginImage.height<OriginImage.width) {
    var height = width*OriginImage.height/OriginImage.width; 
  }
  else {
    var height = width;
    width = height*OriginImage.width/OriginImage.height; 
  }
  
  var height = width*OriginImage.height/OriginImage.width;
  ShowImage.setAttribute("width", width);
  ShowImage.setAttribute("height", height);
  context.drawImage(OriginImage,0,0,OriginImage.width,OriginImage.height,0,0,ShowImage.width,ShowImage.height);
  if (Model) DetectImage();
}
  
window.onload = function () { ObjectDetect(); }
</script>

</body>
</html>

<!-- 
Author : ChungYi Fu (Kaohsiung, Taiwan)   2020/2/10 22:00
https://www.facebook.com/francefu

Try it!
https://fustyles.github.io/webduino/TensorFlow/Face-api/Face-api_FaceRecognition_video.html

How to enable WebGL in Chrome.
https://superuser.com/questions/836832/how-can-i-enable-webgl-in-my-browser

Easy Face Recognition Tutorial With JavaScript
https://www.youtube.com/watch?v=AZ4PdALMqx0
-->
<!DOCTYPE html>
<head>
  <title>Face Recognition</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src='face-api.min.js'></script>
</head>
<body>
<video id="video" width="320" height="240" preload autoplay loop muted></video>
<canvas id="canvas"></canvas><br>
<button id="detect" onclick="this.disabled=true;DetectVideo();" disabled>Start Detection</button><br>
<div id="message" style="width:350px;color:red">Please wait for loading model.</div>

<script>
var video = document.getElementById('video');
var canvas = document.getElementById('canvas'); 
var detect = document.getElementById('detect'); 
var message = document.getElementById('message');
	
const distanceLimit = 0.4;
const faceImagesPath = './facelist/';   
const facelabels = ['France', 'Terry'];
faceImagesCount = 2 ;
// /LabelName/n.jpg  -->  /France/1.jpg, /France/2.jpg, /Terry/1.jpg, /Terry/2.jpg
const modelPath = './';
let displaySize = { width:320, height: 240 };

let labeledFaceDescriptors;
let faceMatcher;

  function loadModel() {
    Promise.all([
      faceapi.nets.faceLandmark68Net.load(modelPath),
      faceapi.nets.faceRecognitionNet.load(modelPath),
      faceapi.nets.ssdMobilenetv1.load(modelPath)
    ]).then(function(){
      startvideo();
    })
  }
  
  function startvideo() {
    navigator.mediaDevices
      .getUserMedia({
        audio: false,
        video: {
          facingMode: "user",
          width: 320,
          height: 240
        }
      })
      .then(stream => {
        video.srcObject = stream
        video.onloadedmetadata = () => {   		
          video.play();
		  detect.disabled=false;
		  message.innerHTML = "";
        }
      })   
  }
                        
  async function DetectVideo() { 

	  canvas.setAttribute("width", video.width);
	  canvas.setAttribute("height", video.height); 
      canvas.getContext('2d').drawImage(video,0,0,video.width,video.height); 

	  if (!labeledFaceDescriptors) {
            message.innerHTML = "Loading face images...";		  
	    labeledFaceDescriptors = await loadLabeledImages();
	    faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, distanceLimit)
	  }

      const detections = await faceapi.detectAllFaces(canvas).withFaceLandmarks().withFaceDescriptors();
      const resizedDetections = faceapi.resizeResults(detections, displaySize);

	  const results = resizedDetections.map(d => faceMatcher.findBestMatch(d.descriptor));
      message.innerHTML = JSON.stringify(results);
	  
      results.forEach((result, i) => {
		const box = resizedDetections[i].detection.box
		var drawBox;
		if (result.distance<=distanceLimit)
			drawBox = new faceapi.draw.DrawBox(box, { label: result.toString()})
		else
			drawBox = new faceapi.draw.DrawBox(box, { label: (Math.round(result.distance*100)/100).toString()})
		drawBox.draw(canvas);
      })

	  setTimeout(function(){DetectVideo(); }, 100);
  }

  function loadLabeledImages() {
	return Promise.all(
		facelabels.map(async label => {
			const descriptions = []
			for (let i=1;i<=faceImagesCount;i++) {
				const img = await faceapi.fetchImage(faceImagesPath+label+'/'+i+'.jpg')
				const detections = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor();
				descriptions.push(detections.descriptor)
			}
			return new faceapi.LabeledFaceDescriptors(label, descriptions)
		})
	)
  }

  window.onload = function () { loadModel(); }
</script>

</body>
</html>

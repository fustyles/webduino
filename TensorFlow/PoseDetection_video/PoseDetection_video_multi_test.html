<!-- 
Author : ChungYi Fu (Kaohsiung, Taiwan)   2019/6/16 23:00
https://www.facebook.com/francefu

Try it!
https://fustyles.github.io/webduino/TensorFlow/PoseDetection_video/PoseDetection_video_multi.html

How to enable WebGL in Chrome.
https://superuser.com/questions/836832/how-can-i-enable-webgl-in-my-browser
-->
<!DOCTYPE html>
<head>
  <title>Multi Pose Detection (Camera)</title>
  <meta charset="utf-8">
  <meta name="robots" content="noindex">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"> </script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"> </script>  
</head>
<body>
<video id="video" width="320" height="240" preload autoplay loop muted></video>
<canvas id="canvas"></canvas>
<br>
<div id="result" style="width:320px;color:red">Please wait for loading model.</div>
  
<script>
  var video = document.getElementById('video');
  var canvas = document.getElementById('canvas'); 
  var context = canvas.getContext('2d');
  var result = document.getElementById('result');
  var Model; 
  
  ObjectDetect();

  function ObjectDetect() {
    posenet.load().then(function(net) {
      Model = net;
      result.innerHTML = "";
      startvideo();
    }); 
  }
  
  function startvideo() {
    video.style.visibility="hidden";
    video.style.position="absolute";
    navigator.mediaDevices
      .getUserMedia({
        audio: false,
        video: {
          facingMode: "user",
          width: 320,
          height: 240
        }
      })
      .then(stream => {
        video.srcObject = stream
        video.onloadedmetadata = () => {       
          video.play();
          canvas.setAttribute("width", video.width);
          canvas.setAttribute("height", video.height);          
          setTimeout(function(){DetectVideo(); }, 100);
        }
      })   
  } 
                        
async function DetectVideo() {
  context.drawImage(video, 0, 0, video.width, video.height);
  await Model.estimatePoses(canvas, {flipHorizontal: false, decodingMethod: 'multi-person', maxPoseDetections: 5, scoreThreshold: 0.5, nmsRadius: 20}).then(pose => {
    result.innerHTML = "";  
    
    //console.log(pose.score);
    //console.log(pose.keypoints);
    if (pose.length>0) {
      for (var n=0;n<pose.length;n++) {
        var k = pose[n].keypoints;
          if (k.length>0) {
            for (var i=0;i<k.length;i++) {
              if (k[i].score>0.1) {
              const x = k[i].position.x;
              const y = k[i].position.y;
              context.fillStyle="#00FFFF";
              context.beginPath();
              context.arc(x, y, 3, 0,2*Math.PI);
              context.closePath();
              context.fill();
            }      
            
            var centerShoulderX = (k[5].position.x+k[6].position.x)/2;
            var centerShoulderY = (k[5].position.y+k[6].position.y)/2;  
            context.beginPath();
            context.arc(centerShoulderX, centerShoulderY, 3, 0,2*Math.PI);
            context.closePath();
            context.fill();
              
            result.innerHTML += "[" + n + "]" + k[i].part + ", " + Math.round(k[i].score*100) + "%, " + Math.round(k[i].position.x) + ", " + Math.round(k[i].position.y) + "<br>";
              
            context.strokeStyle = "#FF0000";
            context.lineWidth = 2;
              
            context.beginPath();
            context.moveTo(k[0].position.x,k[0].position.y);
            context.lineTo(centerShoulderX, centerShoulderY);
            context.stroke();              
              
            context.beginPath();
            context.moveTo(k[5].position.x,k[5].position.y);
            context.lineTo(k[6].position.x,k[6].position.y);
            context.stroke();
              
            context.beginPath();
            context.moveTo(k[5].position.x,k[5].position.y);
            context.lineTo(k[7].position.x,k[7].position.y);
            context.stroke();
            context.beginPath();
            context.moveTo(k[6].position.x,k[6].position.y);
            context.lineTo(k[8].position.x,k[8].position.y);
            context.stroke();
              
            context.beginPath();
            context.moveTo(k[7].position.x,k[7].position.y);
            context.lineTo(k[9].position.x,k[9].position.y);
            context.stroke(); 
            context.beginPath();
            context.moveTo(k[8].position.x,k[8].position.y);
            context.lineTo(k[10].position.x,k[10].position.y);
            context.stroke();    
              
            context.beginPath();
            context.moveTo(k[7].position.x,k[7].position.y);
            context.lineTo(k[9].position.x,k[9].position.y);
            context.stroke(); 
            context.beginPath();
            context.moveTo(k[8].position.x,k[8].position.y);
            context.lineTo(k[10].position.x,k[10].position.y);
            context.stroke();   
              
            context.beginPath();
            context.moveTo(centerShoulderX, centerShoulderY);
            context.lineTo(k[11].position.x,k[11].position.y);
            context.stroke(); 
            context.beginPath();
            context.moveTo(centerShoulderX, centerShoulderY);
            context.lineTo(k[12].position.x,k[12].position.y);
            context.stroke();               
          }
        }
      }
    }  
    setTimeout(function(){DetectVideo(); }, 100);
  });
}

</script>

</body>
</html>

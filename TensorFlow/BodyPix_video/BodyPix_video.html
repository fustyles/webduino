<!-- 
Author : ChungYi Fu (Kaohsiung, Taiwan)   2019/6/7
https://www.facebook.com/francefu

Try it!
https://fustyles.github.io/webduino/TensorFlow/BodyPix_video/BodyPix_video.html
-->
<!DOCTYPE html>
<head>
  <title>person and body part segmentation (BodyPix)</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0"> </script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@1.0.0"> </script>  
</head>
<body>
<video id="video" width="320" height="240" preload autoplay loop muted></video><br>
<div id="result" style="width:320px;color:red">Please wait for loading model.</div><br>
<canvas id="canvas1"></canvas><br>
<canvas id="canvas2"></canvas><br>
<canvas id="canvas3"></canvas>
  
<script>
  var video = document.getElementById('video');
  var canvas1 = document.getElementById('canvas1'); 
  var canvas2 = document.getElementById('canvas2');
  var canvas3 = document.getElementById('canvas3');
  var outputStride = 16;
  var segmentationThreshold = 0.5;

  navigator.mediaDevices
    .getUserMedia({
      audio: false,
      video: {
        facingMode: "user",
        width: 320,
        height: 240
      }
    })
    .then(stream => {
      video.srcObject = stream
      video.onloadedmetadata = () => {       
        video.play();
        ObjectDetect();
      }
    })

  function ObjectDetect() {
    bodyPix.load().then(function(net) {
      Model = net;
      result.innerHTML = "";
      canvas1.setAttribute("width", video.width);
      canvas1.setAttribute("height", video.height);  
      canvas2.setAttribute("width", video.width);
      canvas2.setAttribute("height", video.height);  
      canvas3.setAttribute("width", video.width);
      canvas3.setAttribute("height", video.height);        
      DetectVideo(Model);
    }); 
  }
                        
async function DetectVideo() {
  await Model.estimatePersonSegmentation(video, outputStride, segmentationThreshold).then(segmentation => {
    //console.log(segmentation);

    const maskBackground = true;
    // Convert the personSegmentation into a mask to darken the background.
    // Since maskBackground is set to true, there will be 1s where the background is and 0s where the person is.
    const backgroundDarkeningMask = bodyPix.toMaskImageData(segmentation, maskBackground);
    const opacity = 0.7;
    const maskBlurAmount = 3;
    const flipHorizontal = false;
    const backgroundBlurAmount = 3;
    const edgeBlurAmount = 3;
    // draw the mask onto the image on a canvas.  With opacity set to 0.7 and maskBlurAmount set to 3, this will darken the background and blur the darkened background's edge.
    bodyPix.drawMask(canvas1, video, backgroundDarkeningMask, opacity, maskBlurAmount, flipHorizontal);
    bodyPix.drawBokehEffect(canvas2, video, segmentation, backgroundBlurAmount, edgeBlurAmount, flipHorizontal);
    
    const rainbow = [
      [110, 64, 170], [143, 61, 178], [178, 60, 178], [210, 62, 167],
      [238, 67, 149], [255, 78, 125], [255, 94, 99],  [255, 115, 75],
      [255, 140, 56], [239, 167, 47], [217, 194, 49], [194, 219, 64],
      [175, 240, 91], [135, 245, 87], [96, 247, 96],  [64, 243, 115],
      [40, 234, 141], [28, 219, 169], [26, 199, 194], [33, 176, 213],
      [47, 150, 224], [65, 125, 224], [84, 101, 214], [99, 81, 195]
    ];
    const coloredPartImageData = bodyPix.toColoredPartImageData(segmentation, rainbow);
    const pixelCellWidth = 10.0;
    bodyPix.drawPixelatedMask(canvas3, video, coloredPartImageData, opacity, maskBlurAmount, flipHorizontal, pixelCellWidth);

    try { 
      document.createEvent("TouchEvent");
      segmentationThreshold = 0.5;
    }
    catch(e) { 
      segmentationThreshold = 0.75;
    }   
    DetectVideo();
  });
}
</script>

</body>
</html>
